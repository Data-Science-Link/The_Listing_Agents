{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Iowa House Price (*Base models*) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 1.1: Load libraries and data info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import libraries '''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns   \n",
    "\n",
    "from sklearn.pipeline import Pipeline   \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.model_selection import cross_val_score  \n",
    "from sklearn.model_selection import GridSearchCV    \n",
    "from sklearn.model_selection import RandomizedSearchCV  \n",
    "\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.linear_model import Lasso \n",
    "from sklearn.linear_model import Ridge   \n",
    "from sklearn.linear_model import ElasticNet \n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor    \n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.svm import SVR   \n",
    "from sklearn.ensemble import RandomForestRegressor  \n",
    "from sklearn.ensemble import GradientBoostingRegressor   \n",
    "from sklearn.ensemble import ExtraTreesRegressor \n",
    "from sklearn.ensemble import AdaBoostRegressor    \n",
    "from xgboost import XGBRegressor  \n",
    "from sklearn import metrics   \n",
    "from sklearn.metrics import mean_squared_error  \n",
    "\n",
    "pd.set_option('display.max_columns', 900)   \n",
    "pd.set_option('display.max_rows', 900)\n",
    "\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import df_train and formatted kaggle test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from read_path_module import read_data_relative_path\n",
    "\n",
    "# Manipulated dataset where similar columns are combined\n",
    "df_train = read_data_relative_path(relative_dataset_path = './data/kaggle/created/homes_grouped.csv',\n",
    "                        data_type='csv')\n",
    "\n",
    "from Kaggle_Test_Preprocessing import pre_processing\n",
    "\n",
    "X_test_kaggle = pre_processing(path = './data/kaggle/created/homes_grouping_testdata.csv',\n",
    "                                                  include_variables = 'num_and_chosen_upgradable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Linear_Model_Creation_Function import OLS_Model_Creation\n",
    "\n",
    "lin_reg, X_train, y_train  = OLS_Model_Creation(path = './data/kaggle/created/homes_grouped.csv',\n",
    "                                                include_variables='num_and_chosen_upgradable') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +++ R Squared score for multiple linear regression model +++\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS R^2 = 0.8131984225773061\n"
     ]
    }
   ],
   "source": [
    "SCORE_ols = lin_reg.score(X_train, y_train)\n",
    "print('OLS R^2 =',SCORE_ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Standardize the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Standardarize the dependent variables X '''\n",
    "\n",
    "''' Scaling the data set '''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_standardized = scaler.fit_transform(X_train)     # Note this is .fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +++ Ridge and lasso scores +++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso R^2 = 0.8053982356818056\n",
      "Ridge R^2 = 0.7940707952911531\n",
      "Elastic R^2 = 0.7997932488122184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 867764062098.8414, tolerance: 594717453.8220894\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 893563742599.9285, tolerance: 592726769.6164398\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862195635784.5463, tolerance: 584488620.6451637\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 892974325559.4775, tolerance: 573556280.0626737\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 863203871254.986, tolerance: 574766295.1731464\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()  \n",
    "\n",
    "elasticNet = ElasticNet()   \n",
    "\n",
    "params_eNet = [ {'alpha':[0.001, 0.01, 0.1, 0.5, 1, 10, 100]}, \n",
    "               {'l1_ratio':[0, 0.25, 0.5, 0.75, 1]}]\n",
    "\n",
    "params_lasso = [ {'alpha':[1e-4, 1e-2, 0.1, 1, 2, 20, 30]} ]\n",
    "params_ridge = [ {'alpha':[1e-4, 1e-2, 0.1, 1, 2, 10, 20]} ] \n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "\n",
    "grid_lasso = GridSearchCV(estimator = lasso, param_grid = params_lasso, cv = kfold)\n",
    "grid_ridge = GridSearchCV(estimator = ridge, param_grid = params_ridge, cv = kfold)\n",
    "grid_elasticNet = GridSearchCV(estimator = elasticNet, param_grid = params_eNet, cv = kfold)\n",
    "\n",
    "grid_lasso.fit(X_train, y_train)   \n",
    "grid_ridge.fit(X_train, y_train) \n",
    "grid_elasticNet.fit(X_train, y_train)  \n",
    "\n",
    "SCORE_lasso = grid_lasso.best_score_\n",
    "\n",
    "SCORE_ridge = grid_ridge.best_score_\n",
    "SCORE_elastic = grid_elasticNet.best_score_\n",
    "\n",
    "print('Lasso R^2 =',SCORE_lasso)\n",
    "print('Ridge R^2 =',SCORE_ridge)\n",
    "print('Elastic R^2 =',SCORE_elastic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  +++ Random forest regressor score +++      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R^2 = 0.9762500517541796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define random forest regressor  \n",
    "randomForest = RandomForestRegressor()   \n",
    "\n",
    "# set kfold and hyper-parameter range    \n",
    "kfold = KFold(n_splits = 5, shuffle = True)\n",
    "params_randomForest = [{'n_estimators': [100, 300, 500]},  \n",
    "                       {'max_depth': [10, 20, 30, 40]}, \n",
    "                       {'min_samples_split': [2, 5, 10]}, \n",
    "                       {'min_samples_leaf': [1, 2, 5]}]\n",
    "\n",
    "\n",
    "# grid search \n",
    "grid_randomForest = GridSearchCV(estimator = randomForest, param_grid = params_randomForest, cv = kfold);\n",
    "\n",
    "# fit model \n",
    "grid_randomForest.fit(X_train, y_train);    \n",
    "\n",
    "SCORE_random_forest = grid_randomForest.score(X_train, y_train)\n",
    "\n",
    "print('Random Forest R^2 =',SCORE_random_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +++ Support vector regressor score +++  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR R^2 = 0.6106066551441983\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define random forest regressor  \n",
    "svr = SVR()   \n",
    "\n",
    "# set kfold and hyper-parameter range    \n",
    "kfold = KFold(n_splits = 5, shuffle = True)\n",
    "params_svr = [{'kernel': ['rbf', 'linear']}]\n",
    "              \n",
    "\n",
    "# grid search \n",
    "grid_svr = GridSearchCV(estimator = svr, param_grid = params_svr, cv = kfold)       \n",
    "\n",
    "# fit model \n",
    "grid_svr.fit(X_train, y_train)  \n",
    "\n",
    "SCORE_svr = grid_svr.score(X_train, y_train)\n",
    "\n",
    "print('SVR R^2 =',SCORE_svr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  +++ XG Boost regressor score +++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost R^2 = 0.9119072686947445\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define XGB regressor  \n",
    "xgb_reg = XGBRegressor(objective = 'reg:squarederror')    \n",
    "\n",
    "# set kfold and hyper-parameter range    \n",
    "kfold = KFold(n_splits = 5, shuffle = True)\n",
    "params_xgb_reg = [{'objective': ['reg:squarederror']}, \n",
    "                  {'colsample_bytree': [0.30]}, \n",
    "                  {'learning_rate': [0.1, 0.01]}, \n",
    "                  {'max_depth': [5, 10, 15]},\n",
    "                  {'alpha': [10]}, \n",
    "                  {'n_estimators': [10]}]    \n",
    "              \n",
    "\n",
    "# grid search \n",
    "grid_xgb_reg = GridSearchCV(estimator = xgb_reg, param_grid = params_xgb_reg, cv = kfold)       \n",
    "\n",
    "# fit model \n",
    "grid_xgb_reg.fit(X_train, y_train)  \n",
    "\n",
    "SCORE_xg_boost = grid_xgb_reg.score(X_train, y_train)\n",
    "\n",
    "print('XG Boost R^2 =',SCORE_xg_boost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kaggle_Test_Preprocessing import pre_processing\n",
    "\n",
    "X_test_kaggle = pre_processing(path = './data/kaggle/created/homes_grouping_testdata.csv',\n",
    "                                                  include_variables = 'num_and_chosen_upgradable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_kaggle = grid_xgb_reg.predict(X_test_kaggle)\n",
    "\n",
    "Sample_sbumission = read_data_relative_path(relative_dataset_path = './data/kaggle/sample_submission.csv',\n",
    "                        data_type='csv'\n",
    "                       )\n",
    "\n",
    "ID_kaggle = Sample_sbumission['Id']\n",
    "ID_kaggle\n",
    "\n",
    "Listing_Agents_Submission = pd.DataFrame(ID_kaggle)\n",
    "Listing_Agents_Submission['SalePrice'] = y_predict_kaggle\n",
    "Listing_Agents_Submission.to_csv('XG_Boost_Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_kaggle = grid_randomForest.predict(X_test_kaggle)\n",
    "\n",
    "Sample_sbumission = read_data_relative_path(relative_dataset_path = './data/kaggle/sample_submission.csv',\n",
    "                        data_type='csv'\n",
    "                       )\n",
    "\n",
    "ID_kaggle = Sample_sbumission['Id']\n",
    "ID_kaggle\n",
    "\n",
    "Listing_Agents_Submission = pd.DataFrame(ID_kaggle)\n",
    "Listing_Agents_Submission['SalePrice'] = y_predict_kaggle\n",
    "Listing_Agents_Submission.to_csv('randomForest_Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of all the models in this notebook:\n",
    "- Multiple linear regression [ lin_reg ]\n",
    "- Ridge [ grid_ridge ]\n",
    "- Lasso [ grid_lasso ]\n",
    "- Elastic net [ grid_elasticNet ]\n",
    "- Random forest [ grid_randomForest ]\n",
    "- Support vector regressor [ grid_svr ]\n",
    "- XG Boost Regressor [ grid_xgb_reg ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each of the above models were trained on X_train & y_train\n",
    "\n",
    "#### We want to assemble a table of R^2 per model and to extract p-value significance for each variable in each model\n",
    "- To do so we will create list of model names,\n",
    "- Evaluate each score on X_train and y_train\n",
    "- Separately come up with function to perform stats module actions\n",
    "- Create for loop to horizontally merge p value columns from each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested for loop to fit models based on y_train or log of y_train and to save the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fitting and scoring the  lin_reg  model with  y_train  data.\n",
      "Completed fitting and scoring the  grid_ridge  model with  y_train  data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 204849253614.01392, tolerance: 476000656.9165306\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 221400940296.42038, tolerance: 503903214.1295112\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 208210423183.5628, tolerance: 484085623.24186504\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154578967314.84158, tolerance: 484343019.1950789\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164716790883.97366, tolerance: 479999588.31347495\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162577617537.39233, tolerance: 476000656.9165306\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 169680147847.28326, tolerance: 503903214.1295112\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86251777400.56274, tolerance: 484085623.24186504\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19722664074.79178, tolerance: 484343019.1950789\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66103314794.44571, tolerance: 479999588.31347495\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77139544253.08969, tolerance: 476000656.9165306\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40754562177.30762, tolerance: 503903214.1295112\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64061428192.19382, tolerance: 484085623.24186504\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19632354570.9794, tolerance: 484343019.1950789\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66133945040.25134, tolerance: 479999588.31347495\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 62698761242.524414, tolerance: 476000656.9165306\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40382791170.139496, tolerance: 503903214.1295112\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64347589448.08096, tolerance: 484085623.24186504\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20448527688.493896, tolerance: 484343019.1950789\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66360859008.32376, tolerance: 479999588.31347495\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61536607553.982544, tolerance: 476000656.9165306\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26296033740.212646, tolerance: 503903214.1295112\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64570577612.66055, tolerance: 484085623.24186504\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3577961071.8695984, tolerance: 484343019.1950789\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66749520788.888, tolerance: 479999588.31347495\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1396468276.6000977, tolerance: 476000656.9165306\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1598578441.8510132, tolerance: 503903214.1295112\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 870971185.9390259, tolerance: 484085623.24186504\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 899071454.2306519, tolerance: 484343019.1950789\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1470272541.2926025, tolerance: 479999588.31347495\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 987171259.3525391, tolerance: 484085623.24186504\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1271150053.6444092, tolerance: 484343019.1950789\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1567450004.801941, tolerance: 479999588.31347495\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 210729059272.69363, tolerance: 485186057.91945255\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 223579581398.9614, tolerance: 504938389.38459826\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fitting and scoring the  grid_lasso  model with  y_train  data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 206959098844.85657, tolerance: 492410458.11100686\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 215753364183.2885, tolerance: 475301188.4427776\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161366679344.15826, tolerance: 470634843.8877508\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 211801529386.9644, tolerance: 485186057.91945255\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 221157383275.76978, tolerance: 504938389.38459826\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 211576174657.81534, tolerance: 492410458.11100686\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 217260296710.49762, tolerance: 475301188.4427776\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154913409098.75986, tolerance: 470634843.8877508\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 529680624415.1562, tolerance: 485186057.91945255\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 549327558529.3429, tolerance: 504938389.38459826\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 530117178849.8181, tolerance: 492410458.11100686\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 500792416613.8327, tolerance: 475301188.4427776\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 498904408965.87164, tolerance: 470634843.8877508\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26427037417.62375, tolerance: 485186057.91945255\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68098563858.147064, tolerance: 504938389.38459826\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16872913160.545288, tolerance: 492410458.11100686\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23326357161.987244, tolerance: 475301188.4427776\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49178010905.01425, tolerance: 470634843.8877508\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fitting and scoring the  grid_elasticNet  model with  y_train  data.\n",
      "Completed fitting and scoring the  grid_randomForest  model with  y_train  data.\n",
      "Completed fitting and scoring the  grid_svr  model with  y_train  data.\n",
      "Completed fitting and scoring the  lin_reg  model with  np.log(y_train)  data.\n",
      "Completed fitting and scoring the  grid_ridge  model with  np.log(y_train)  data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02409466042176156, tolerance: 0.014208027057050189\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04057820062877937, tolerance: 0.01391654748390081\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02050783586429361, tolerance: 0.014626586294173512\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04340094515073645, tolerance: 0.013857510247022385\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fitting and scoring the  grid_lasso  model with  np.log(y_train)  data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.827228703523929, tolerance: 0.01444456231003957\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.550613874798447, tolerance: 0.013641217880497759\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.83017703077482, tolerance: 0.014151390767391019\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.012041203840733, tolerance: 0.01410430701440036\n",
      "  positive)\n",
      "/Users/michaellink/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.066175226650602, tolerance: 0.01449098842966355\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fitting and scoring the  grid_elasticNet  model with  np.log(y_train)  data.\n",
      "Completed fitting and scoring the  grid_randomForest  model with  np.log(y_train)  data.\n",
      "Completed fitting and scoring the  grid_svr  model with  np.log(y_train)  data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R^2 y_train</th>\n",
       "      <th>R^2 log(y_train)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lin_reg</th>\n",
       "      <td>0.9123</td>\n",
       "      <td>-6.0512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_ridge</th>\n",
       "      <td>0.8069</td>\n",
       "      <td>0.8659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_lasso</th>\n",
       "      <td>0.8239</td>\n",
       "      <td>0.8593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_elasticNet</th>\n",
       "      <td>0.8503</td>\n",
       "      <td>0.8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_randomForest</th>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.8688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_svr</th>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.8462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   R^2 y_train  R^2 log(y_train)\n",
       "Model                                           \n",
       "lin_reg                 0.9123           -6.0512\n",
       "grid_ridge              0.8069            0.8659\n",
       "grid_lasso              0.8239            0.8593\n",
       "grid_elasticNet         0.8503            0.8590\n",
       "grid_randomForest       0.8527            0.8688\n",
       "grid_svr                0.1750            0.8462"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_names = ['lin_reg', 'grid_ridge', 'grid_lasso', 'grid_elasticNet', 'grid_randomForest', 'grid_svr'] \n",
    "#model_names = ['lin_reg', 'grid_ridge', 'grid_svr'] \n",
    "model_trans = ['y_train']\n",
    "\n",
    "for y_vals in model_trans:\n",
    "    \n",
    "    model_scores = []\n",
    "\n",
    "    for model in model_names:\n",
    "        if model == 'lin_reg':\n",
    "            eval(model+'.fit(X_train,'+y_vals+')')\n",
    "            score = eval(model+'.score(X_train, y_train)')\n",
    "            model_scores.append(round(score,4))\n",
    "            print('Completed fitting and scoring the ', model, ' model with ', y_vals, ' data.')\n",
    "        else:\n",
    "            eval(model+'.fit(X_train,'+y_vals+')')\n",
    "            score = eval(model+'.best_score_')\n",
    "            model_scores.append(round(score,4))\n",
    "            print('Completed fitting and scoring the ', model, ' model with ', y_vals, ' data.')\n",
    "        \n",
    "    if y_vals == 'y_train':\n",
    "        No_Transformation_DF = pd.DataFrame({'Model': model_names, 'R^2': model_scores})\n",
    "        No_Transformation_DF = No_Transformation_DF.set_index('Model')\n",
    "        No_Transformation_DF = No_Transformation_DF.rename(columns={\"R^2\": \"R^2 y_train\"})\n",
    "    else:\n",
    "        Log_Transformation_DF = pd.DataFrame({'Model': model_names, 'R^2': model_scores})\n",
    "        Log_Transformation_DF = Log_Transformation_DF.set_index('Model')\n",
    "        Log_Transformation_DF = Log_Transformation_DF.rename(columns={\"R^2\": \"R^2 log(y_train)\"})\n",
    "\n",
    "        \n",
    "Score_df = pd.concat([No_Transformation_DF, Log_Transformation_DF], axis=1, sort=False)\n",
    "Score_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              SalePrice   R-squared:                       0.934\n",
      "Model:                            OLS   Adj. R-squared:                  0.917\n",
      "Method:                 Least Squares   F-statistic:                     53.41\n",
      "Date:                Wed, 27 May 2020   Prob (F-statistic):               0.00\n",
      "Time:                        01:15:59   Log-Likelihood:                -13246.\n",
      "No. Observations:                1168   AIC:                         2.698e+04\n",
      "Df Residuals:                     922   BIC:                         2.823e+04\n",
      "Df Model:                         245                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.821e+05    670.968    271.339      0.000    1.81e+05    1.83e+05\n",
      "x1         -3451.8287   4099.625     -0.842      0.400   -1.15e+04    4593.850\n",
      "x2          -125.3910    837.488     -0.150      0.881   -1768.994    1518.212\n",
      "x3          5715.4281   1431.920      3.991      0.000    2905.227    8525.629\n",
      "x4          9668.9914   1638.593      5.901      0.000    6453.186    1.29e+04\n",
      "x5          5475.0377   1174.436      4.662      0.000    3170.161    7779.915\n",
      "x6          8156.9631   2659.741      3.067      0.002    2937.115    1.34e+04\n",
      "x7          2359.1376   1368.022      1.724      0.085    -325.660    5043.936\n",
      "x8          5092.2404   1199.840      4.244      0.000    2737.506    7446.975\n",
      "x9          7179.7977   1274.536      5.633      0.000    4678.469    9681.127\n",
      "x10         1089.4129   1413.151      0.771      0.441   -1683.953    3862.779\n",
      "x11          273.3316   1111.530      0.246      0.806   -1908.090    2454.753\n",
      "x12         8068.9916   1816.586      4.442      0.000    4503.869    1.16e+04\n",
      "x13         5675.2511   1974.102      2.875      0.004    1800.997    9549.505\n",
      "x14         1.475e+04   1976.899      7.463      0.000    1.09e+04    1.86e+04\n",
      "x15         -502.9586   1008.934     -0.499      0.618   -2483.032    1477.115\n",
      "x16         1.656e+04   1492.359     11.097      0.000    1.36e+04    1.95e+04\n",
      "x17         1294.3776   1183.636      1.094      0.274   -1028.556    3617.311\n",
      "x18          435.0821    841.727      0.517      0.605   -1216.841    2087.006\n",
      "x19         2193.3943   1388.665      1.579      0.115    -531.917    4918.706\n",
      "x20          427.8360   1205.702      0.355      0.723   -1938.403    2794.075\n",
      "x21        -3016.9947   1299.829     -2.321      0.021   -5567.962    -466.027\n",
      "x22        -2661.4890   1542.338     -1.726      0.085   -5688.389     365.411\n",
      "x23         2159.8663   1788.751      1.207      0.228   -1350.630    5670.362\n",
      "x24         3699.5939   1909.725      1.937      0.053     -48.317    7447.505\n",
      "x25         -981.6954   1492.633     -0.658      0.511   -3911.048    1947.657\n",
      "x26         1226.4064   1998.641      0.614      0.540   -2696.008    5148.821\n",
      "x27         4779.9698   1931.067      2.475      0.013     990.174    8569.766\n",
      "x28         1983.3546    859.526      2.307      0.021     296.499    3670.210\n",
      "x29           39.4026    925.764      0.043      0.966   -1777.446    1856.251\n",
      "x30         1206.1821    884.274      1.364      0.173    -529.241    2941.605\n",
      "x31          918.5111    757.267      1.213      0.225    -567.656    2404.679\n",
      "x32         1983.2964    801.889      2.473      0.014     409.558    3557.035\n",
      "x33         1.113e+04   1.01e+04      1.101      0.271   -8720.409     3.1e+04\n",
      "x34         1569.6736   3578.048      0.439      0.661   -5452.390    8591.738\n",
      "x35        -1349.0632    766.638     -1.760      0.079   -2853.622     155.496\n",
      "x36         -577.2101    792.074     -0.729      0.466   -2131.687     977.267\n",
      "x37         5348.0212   3049.865      1.754      0.080    -637.463    1.13e+04\n",
      "x38         1670.2450   1464.669      1.140      0.254   -1204.226    4544.716\n",
      "x39         7374.2532   5082.777      1.451      0.147   -2600.902    1.73e+04\n",
      "x40         4997.2789   4085.933      1.223      0.222   -3021.530     1.3e+04\n",
      "x41         1837.8704    907.932      2.024      0.043      56.016    3619.724\n",
      "x42         -708.0792   1210.200     -0.585      0.559   -3083.145    1666.987\n",
      "x43         -601.7574   1154.376     -0.521      0.602   -2867.267    1663.752\n",
      "x44          942.4733    799.762      1.178      0.239    -627.092    2512.039\n",
      "x45         1356.0846    920.063      1.474      0.141    -449.577    3161.746\n",
      "x46         1295.9201    910.712      1.423      0.155    -491.389    3083.229\n",
      "x47         2674.1298   1130.585      2.365      0.018     455.312    4892.948\n",
      "x48         -802.4440   1178.463     -0.681      0.496   -3115.226    1510.338\n",
      "x49         2703.3879   1336.829      2.022      0.043      79.806    5326.969\n",
      "x50        -1211.4632    811.577     -1.493      0.136   -2804.215     381.289\n",
      "x51         1683.6168    896.722      1.878      0.061     -76.237    3443.470\n",
      "x52        -1483.3783    825.149     -1.798      0.073   -3102.767     136.010\n",
      "x53         -951.1885    765.687     -1.242      0.214   -2453.880     551.503\n",
      "x54        -1191.6442    915.717     -1.301      0.193   -2988.776     605.488\n",
      "x55         1154.1338    966.199      1.195      0.233    -742.071    3050.339\n",
      "x56        -1810.2711   1314.673     -1.377      0.169   -4390.369     769.827\n",
      "x57          155.6132    838.255      0.186      0.853   -1489.496    1800.723\n",
      "x58         -425.1825   1412.082     -0.301      0.763   -3196.450    2346.086\n",
      "x59        -1564.7049   2134.209     -0.733      0.464   -5753.176    2623.767\n",
      "x60        -1965.3550   1461.811     -1.344      0.179   -4834.218     903.508\n",
      "x61        -3435.3609   2564.642     -1.340      0.181   -8468.574    1597.852\n",
      "x62         1977.3110   1957.476      1.010      0.313   -1864.315    5818.937\n",
      "x63        -5670.0402   2442.726     -2.321      0.020   -1.05e+04    -876.091\n",
      "x64        -2592.9658   2077.773     -1.248      0.212   -6670.679    1484.747\n",
      "x65        -2163.7434   2017.780     -1.072      0.284   -6123.718    1796.231\n",
      "x66         -596.1637   1473.485     -0.405      0.686   -3487.938    2295.610\n",
      "x67        -3849.2817   1748.602     -2.201      0.028   -7280.983    -417.580\n",
      "x68        -6525.5725   3421.018     -1.907      0.057   -1.32e+04     188.313\n",
      "x69         1247.2585   1376.294      0.906      0.365   -1453.775    3948.292\n",
      "x70        -4098.1409   2106.633     -1.945      0.052   -8232.493      36.211\n",
      "x71         3303.4012   1631.194      2.025      0.043     102.117    6504.685\n",
      "x72         4418.3499   2065.551      2.139      0.033     364.624    8472.076\n",
      "x73        -4755.8482   2989.383     -1.591      0.112   -1.06e+04    1110.936\n",
      "x74        -1514.5695   1406.416     -1.077      0.282   -4274.718    1245.579\n",
      "x75        -2116.5367   2100.747     -1.008      0.314   -6239.337    2006.263\n",
      "x76         -419.3129   1787.148     -0.235      0.815   -3926.662    3088.036\n",
      "x77         -592.7851   2469.958     -0.240      0.810   -5440.177    4254.607\n",
      "x78         4395.4045   1284.755      3.421      0.001    1874.022    6916.787\n",
      "x79        -1765.5849   1560.148     -1.132      0.258   -4827.439    1296.269\n",
      "x80         -586.8581   1125.660     -0.521      0.602   -2796.011    1622.295\n",
      "x81         1564.0517   1329.536      1.176      0.240   -1045.216    4173.319\n",
      "x82         4986.5879   1662.604      2.999      0.003    1723.660    8249.516\n",
      "x83         1238.6080    867.116      1.428      0.154    -463.142    2940.358\n",
      "x84          930.5449    995.954      0.934      0.350   -1024.055    2885.145\n",
      "x85        -1060.6866    856.834     -1.238      0.216   -2742.257     620.884\n",
      "x86         1603.1556   1074.006      1.493      0.136    -504.625    3710.936\n",
      "x87         -278.9526    752.121     -0.371      0.711   -1755.021    1197.116\n",
      "x88          915.2936    860.839      1.063      0.288    -774.137    2604.724\n",
      "x89         1348.8626    713.215      1.891      0.059     -50.851    2748.577\n",
      "x90         1732.8734    456.811      3.793      0.000     836.364    2629.383\n",
      "x91         1784.3987    971.233      1.837      0.066    -121.684    3690.482\n",
      "x92        -8263.9576    766.366    -10.783      0.000   -9767.982   -6759.933\n",
      "x93        -2.898e-11   5.51e-11     -0.526      0.599   -1.37e-10    7.92e-11\n",
      "x94          148.1478    716.515      0.207      0.836   -1258.041    1554.337\n",
      "x95          729.8929    726.759      1.004      0.315    -696.401    2156.187\n",
      "x96          478.0291   1953.151      0.245      0.807   -3355.109    4311.167\n",
      "x97         -594.0635   1538.553     -0.386      0.699   -3613.536    2425.408\n",
      "x98        -3007.1895   2067.836     -1.454      0.146   -7065.401    1051.022\n",
      "x99        -3975.0324   2779.816     -1.430      0.153   -9430.533    1480.468\n",
      "x100        1433.7762    818.250      1.752      0.080    -172.072    3039.625\n",
      "x101        4527.9181   2628.771      1.722      0.085    -631.151    9686.987\n",
      "x102       -1358.3099    980.631     -1.385      0.166   -3282.838     566.218\n",
      "x103       -1289.6302   1049.637     -1.229      0.220   -3349.585     770.324\n",
      "x104       -1388.8401   1871.752     -0.742      0.458   -5062.229    2284.549\n",
      "x105         795.1829   1200.568      0.662      0.508   -1560.980    3151.346\n",
      "x106        1621.2145   1357.533      1.194      0.233   -1042.998    4285.427\n",
      "x107         647.5944   8774.589      0.074      0.941   -1.66e+04    1.79e+04\n",
      "x108         655.2428   2050.291      0.320      0.749   -3368.536    4679.022\n",
      "x109         400.6865   8530.125      0.047      0.963   -1.63e+04    1.71e+04\n",
      "x110        1043.8585   1676.707      0.623      0.534   -2246.746    4334.463\n",
      "x111        2128.4787   1104.639      1.927      0.054     -39.420    4296.377\n",
      "x112        7.221e+04   6643.314     10.870      0.000    5.92e+04    8.52e+04\n",
      "x113        2.017e+04   1986.161     10.154      0.000    1.63e+04    2.41e+04\n",
      "x114       -3.964e-12   4.44e-11     -0.089      0.929   -9.11e-11    8.32e-11\n",
      "x115        1.779e+04   1847.839      9.626      0.000    1.42e+04    2.14e+04\n",
      "x116        4.019e+04   4067.148      9.881      0.000    3.22e+04    4.82e+04\n",
      "x117        3.523e+04   3521.394     10.005      0.000    2.83e+04    4.21e+04\n",
      "x118        4.022e+04   3393.708     11.852      0.000    3.36e+04    4.69e+04\n",
      "x119        -878.7670   1242.552     -0.707      0.480   -3317.326    1559.792\n",
      "x120        -727.4690   1163.853     -0.625      0.532   -3011.577    1556.638\n",
      "x121         825.8094   3396.725      0.243      0.808   -5840.400    7492.019\n",
      "x122        -319.5642    434.201     -0.736      0.462   -1171.701     532.573\n",
      "x123       -2025.1562   4721.625     -0.429      0.668   -1.13e+04    7241.223\n",
      "x124       -5119.8496   6879.540     -0.744      0.457   -1.86e+04    8381.524\n",
      "x125        -491.9946    939.953     -0.523      0.601   -2336.690    1352.701\n",
      "x126       -4423.4504   7298.591     -0.606      0.545   -1.87e+04    9900.328\n",
      "x127       -4060.2119   4833.560     -0.840      0.401   -1.35e+04    5425.844\n",
      "x128        -400.1309   1042.221     -0.384      0.701   -2445.532    1645.270\n",
      "x129       -1046.0096   2652.869     -0.394      0.693   -6252.372    4160.353\n",
      "x130       -7815.1320   9794.370     -0.798      0.425    -2.7e+04    1.14e+04\n",
      "x131       -7187.4988   6277.127     -1.145      0.252   -1.95e+04    5131.615\n",
      "x132       -1507.8263   2702.253     -0.558      0.577   -6811.107    3795.454\n",
      "x133         995.4745   1399.278      0.711      0.477   -1750.664    3741.613\n",
      "x134         321.7595   1865.188      0.173      0.863   -3338.746    3982.265\n",
      "x135        1332.9215   2533.307      0.526      0.599   -3638.796    6304.639\n",
      "x136        -319.5642    434.201     -0.736      0.462   -1171.701     532.573\n",
      "x137        1509.7821   4738.932      0.319      0.750   -7790.562    1.08e+04\n",
      "x138        3125.9189   6824.399      0.458      0.647   -1.03e+04    1.65e+04\n",
      "x139         707.8857   1819.919      0.389      0.697   -2863.778    4279.550\n",
      "x140        3525.6262   7336.640      0.481      0.631   -1.09e+04    1.79e+04\n",
      "x141        -325.5575    944.009     -0.345      0.730   -2178.212    1527.097\n",
      "x142        2894.5198   5506.641      0.526      0.599   -7912.484    1.37e+04\n",
      "x143        -110.2079   1541.202     -0.072      0.943   -3134.879    2914.464\n",
      "x144        1603.9506   2811.660      0.570      0.569   -3914.046    7121.947\n",
      "x145        6935.1596   9855.397      0.704      0.482   -1.24e+04    2.63e+04\n",
      "x146        6630.1135   6267.183      1.058      0.290   -5669.486    1.89e+04\n",
      "x147         815.9870   3161.682      0.258      0.796   -5388.941    7020.915\n",
      "x148        2785.1384   3322.822      0.838      0.402   -3736.033    9306.310\n",
      "x149        4325.4622   3572.226      1.211      0.226   -2685.175    1.13e+04\n",
      "x150       -1975.3454    904.601     -2.184      0.029   -3750.661    -200.029\n",
      "x151        2349.6433   2201.416      1.067      0.286   -1970.724    6670.010\n",
      "x152        -996.8570   1322.487     -0.754      0.451   -3592.290    1598.576\n",
      "x153       -1.235e+04   2594.585     -4.759      0.000   -1.74e+04   -7256.263\n",
      "x154        -1.36e+04   2961.826     -4.591      0.000   -1.94e+04   -7783.814\n",
      "x155        -270.9648   2608.032     -0.104      0.917   -5389.332    4847.402\n",
      "x156       -1435.2731   5348.297     -0.268      0.788   -1.19e+04    9060.975\n",
      "x157         190.7089    980.958      0.194      0.846   -1734.461    2115.879\n",
      "x158       -1332.5103   5821.925     -0.229      0.819   -1.28e+04    1.01e+04\n",
      "x159         733.6583   1958.882      0.375      0.708   -3110.726    4578.042\n",
      "x160        1775.9372   2097.355      0.847      0.397   -2340.206    5892.081\n",
      "x161       -1838.7268   1474.016     -1.247      0.213   -4731.543    1054.090\n",
      "x162         276.0336    927.395      0.298      0.766   -1544.016    2096.083\n",
      "x163       -1111.2676    789.898     -1.407      0.160   -2661.474     438.939\n",
      "x164       -1653.7123   1131.375     -1.462      0.144   -3874.080     566.656\n",
      "x165       -8484.8048   1920.473     -4.418      0.000   -1.23e+04   -4715.799\n",
      "x166         927.2773   1252.520      0.740      0.459   -1530.843    3385.398\n",
      "x167       -6476.6831   2376.412     -2.725      0.007   -1.11e+04   -1812.878\n",
      "x168         215.2765   1320.603      0.163      0.871   -2376.460    2807.013\n",
      "x169         927.2773   1252.520      0.740      0.459   -1530.843    3385.398\n",
      "x170         516.9271    751.014      0.688      0.491    -956.967    1990.822\n",
      "x171        1725.5105   1601.207      1.078      0.281   -1416.924    4867.944\n",
      "x172        5035.5747   1000.806      5.032      0.000    3071.452    6999.697\n",
      "x173        -926.5527    914.142     -1.014      0.311   -2720.594     867.488\n",
      "x174       -2337.5033   1195.353     -1.955      0.051   -4683.433       8.426\n",
      "x175         927.2773   1252.520      0.740      0.459   -1530.843    3385.398\n",
      "x176         533.6671    975.945      0.547      0.585   -1381.664    2448.998\n",
      "x177        3239.0700   1301.466      2.489      0.013     684.890    5793.250\n",
      "x178        -552.2807    955.518     -0.578      0.563   -2427.523    1322.962\n",
      "x179         927.2773   1252.520      0.740      0.459   -1530.843    3385.398\n",
      "x180         -76.0535    996.497     -0.076      0.939   -2031.719    1879.612\n",
      "x181        1343.1409   1551.180      0.866      0.387   -1701.112    4387.394\n",
      "x182       -2224.3737   1395.269     -1.594      0.111   -4962.646     513.898\n",
      "x183          50.0627   1121.353      0.045      0.964   -2150.637    2250.762\n",
      "x184       -1816.1782   1549.634     -1.172      0.241   -4857.397    1225.041\n",
      "x185       -3901.6664   4272.770     -0.913      0.361   -1.23e+04    4483.817\n",
      "x186       -1315.0060   1597.019     -0.823      0.410   -4449.220    1819.208\n",
      "x187       -2516.0596   3121.887     -0.806      0.420   -8642.889    3610.770\n",
      "x188        -314.2279   3910.269     -0.080      0.936   -7988.288    7359.832\n",
      "x189        -166.7563   3055.150     -0.055      0.956   -6162.611    5829.098\n",
      "x190        -182.4049   1966.098     -0.093      0.926   -4040.951    3676.141\n",
      "x191         -40.2312   1130.389     -0.036      0.972   -2258.666    2178.203\n",
      "x192        1209.2143   1843.140      0.656      0.512   -2408.023    4826.452\n",
      "x193        -127.5769    950.571     -0.134      0.893   -1993.111    1737.958\n",
      "x194       -1434.9784    887.240     -1.617      0.106   -3176.223     306.266\n",
      "x195       -8.252e-12   9.28e-12     -0.889      0.374   -2.65e-11    9.96e-12\n",
      "x196        -661.0105   1074.897     -0.615      0.539   -2770.539    1448.518\n",
      "x197        1636.2016   1155.760      1.416      0.157    -632.024    3904.427\n",
      "x198        -267.8988    913.010     -0.293      0.769   -2059.719    1523.921\n",
      "x199        -268.4370   1451.245     -0.185      0.853   -3116.563    2579.689\n",
      "x200         516.9271    751.014      0.688      0.491    -956.967    1990.822\n",
      "x201         472.8914    725.611      0.652      0.515    -951.149    1896.932\n",
      "x202        -253.1499    998.961     -0.253      0.800   -2213.651    1707.351\n",
      "x203       -2043.9677   1143.915     -1.787      0.074   -4288.947     201.012\n",
      "x204       -1.038e+04   2005.562     -5.177      0.000   -1.43e+04   -6446.836\n",
      "x205       -1.026e+04   2297.855     -4.463      0.000   -1.48e+04   -5746.123\n",
      "x206        -557.2102    995.409     -0.560      0.576   -2510.740    1396.319\n",
      "x207        1060.1359   1337.913      0.792      0.428   -1565.571    3685.843\n",
      "x208        1510.6581   1486.691      1.016      0.310   -1407.032    4428.348\n",
      "x209        -510.3472   1271.641     -0.401      0.688   -3005.994    1985.300\n",
      "x210       -1246.5315   1018.373     -1.224      0.221   -3245.129     752.066\n",
      "x211        4584.5978   2058.227      2.227      0.026     545.244    8623.951\n",
      "x212       -1724.2021   1238.983     -1.392      0.164   -4155.756     707.352\n",
      "x213       -3931.4765   2914.045     -1.349      0.178   -9650.408    1787.455\n",
      "x214       -1767.8238   3750.157     -0.471      0.637   -9127.658    5592.010\n",
      "x215        -205.6788   1110.461     -0.185      0.853   -2385.003    1973.645\n",
      "x216       -3384.3249   2825.044     -1.198      0.231   -8928.587    2159.938\n",
      "x217        7204.3721   6254.115      1.152      0.250   -5069.581    1.95e+04\n",
      "x218        2305.1277   1771.653      1.301      0.194   -1171.813    5782.069\n",
      "x219        2946.2622   3286.298      0.897      0.370   -3503.230    9395.754\n",
      "x220        1457.3808   1304.668      1.117      0.264   -1103.083    4017.845\n",
      "x221        7632.8891   5614.128      1.360      0.174   -3385.063    1.87e+04\n",
      "x222         893.8091   1638.300      0.546      0.585   -2321.421    4109.039\n",
      "x223         893.8091   1638.300      0.546      0.585   -2321.421    4109.039\n",
      "x224        -785.7258   1011.921     -0.776      0.438   -2771.662    1200.211\n",
      "x225        -162.5264   1362.045     -0.119      0.905   -2835.595    2510.542\n",
      "x226        -810.5244   2159.420     -0.375      0.707   -5048.472    3427.423\n",
      "x227         406.0847   1365.255      0.297      0.766   -2273.284    3085.454\n",
      "x228         893.8091   1638.300      0.546      0.585   -2321.421    4109.039\n",
      "x229        -828.5099   1939.286     -0.427      0.669   -4634.436    2977.416\n",
      "x230        -664.1877   3474.432     -0.191      0.848   -7482.899    6154.524\n",
      "x231       -1025.2610   2137.576     -0.480      0.632   -5220.341    3169.819\n",
      "x232          41.2129   1270.987      0.032      0.974   -2453.150    2535.576\n",
      "x233         893.8091   1638.300      0.546      0.585   -2321.421    4109.039\n",
      "x234        -497.1390   1532.726     -0.324      0.746   -3505.176    2510.898\n",
      "x235        -547.6130   3823.804     -0.143      0.886   -8051.983    6956.757\n",
      "x236       -1411.3818    943.724     -1.496      0.135   -3263.479     440.715\n",
      "x237        -604.4294   1139.159     -0.531      0.596   -2840.075    1631.216\n",
      "x238       -3040.3315   1575.322     -1.930      0.054   -6131.965      51.302\n",
      "x239       -1.062e+04   2057.608     -5.162      0.000   -1.47e+04   -6582.397\n",
      "x240       -4738.7640   9819.136     -0.483      0.629    -2.4e+04    1.45e+04\n",
      "x241         901.5874   1117.834      0.807      0.420   -1292.206    3095.381\n",
      "x242        1924.2217   1486.340      1.295      0.196    -992.781    4841.225\n",
      "x243          37.8606    818.586      0.046      0.963   -1568.648    1644.369\n",
      "x244        2314.5316   1715.668      1.349      0.178   -1052.535    5681.598\n",
      "x245        9267.4233   2.23e+04      0.415      0.678   -3.45e+04     5.3e+04\n",
      "x246        2324.3109   4426.600      0.525      0.600   -6363.069     1.1e+04\n",
      "x247        8809.0702   2.05e+04      0.430      0.667   -3.14e+04     4.9e+04\n",
      "x248       -3040.3315   1575.322     -1.930      0.054   -6131.965      51.302\n",
      "x249        1023.4478    787.567      1.300      0.194    -522.184    2569.080\n",
      "x250        1290.1105    775.892      1.663      0.097    -232.609    2812.830\n",
      "x251         662.6249    913.468      0.725      0.468   -1130.094    2455.344\n",
      "x252         478.7805    776.270      0.617      0.538   -1044.681    2002.242\n",
      "x253         218.5011    762.233      0.287      0.774   -1277.412    1714.414\n",
      "x254       -2324.9106   5302.788     -0.438      0.661   -1.27e+04    8082.024\n",
      "x255          93.2584    741.284      0.126      0.900   -1361.541    1548.058\n",
      "x256         385.6627   1638.774      0.235      0.814   -2830.498    3601.823\n",
      "x257        -176.0620   1254.258     -0.140      0.888   -2637.595    2285.471\n",
      "x258        -135.2545    937.052     -0.144      0.885   -1974.258    1703.748\n",
      "x259        -864.4182    818.024     -1.057      0.291   -2469.824     740.988\n",
      "x260        2381.7799   1307.821      1.821      0.069    -184.871    4948.431\n",
      "x261        8432.3095   5192.547      1.624      0.105   -1758.274    1.86e+04\n",
      "==============================================================================\n",
      "Omnibus:                      303.017   Durbin-Watson:                   2.048\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12701.772\n",
      "Skew:                           0.392   Prob(JB):                         0.00\n",
      "Kurtosis:                      19.136   Cond. No.                     4.30e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.08e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Function to get printout of OLS statistical significance\n",
    "\n",
    "def R_stats_printout(X_data, y_data, transformation_method = 'linear'):\n",
    "    '''\n",
    "    Transformation method can be linear or log transformation\n",
    "    '''\n",
    "    if transformation_method == 'linear':\n",
    "        import statsmodels.api as sm\n",
    "        x = sm.add_constant(X_data)\n",
    "        model = sm.OLS(y_data, x)\n",
    "        results = model.fit()\n",
    "        print(results.summary())\n",
    "    else:\n",
    "        import statsmodels.api as sm\n",
    "        x = sm.add_constant(X_data)\n",
    "        model = sm.OLS(np.log(y_data), x)\n",
    "        results = model.fit()\n",
    "        print(results.summary())\n",
    "    \n",
    "\n",
    "R_stats_printout(X_train, y_train)\n",
    "\n",
    "def R_stats_P_values(X_data, y_data, transformation_method = 'linear'):\n",
    "    '''\n",
    "    Transformation method can be linear or log transformation\n",
    "    '''\n",
    "    if transformation_method == 'linear':\n",
    "        import statsmodels.api as sm\n",
    "        x = sm.add_constant(X_data)\n",
    "        model = sm.OLS(y_data, x)\n",
    "        results = model.fit()\n",
    "        pValues = results.pvalues\n",
    "        return pValues\n",
    "    else:\n",
    "        import statsmodels.api as sm\n",
    "        x = sm.add_constant(X_data)\n",
    "        model = sm.OLS(np.log(y_data), x)\n",
    "        results = model.fit()\n",
    "        pValues = results.pvalues\n",
    "        return pValues\n",
    "\n",
    "    \n",
    "P_values = R_stats_P_values(X_data, y_data)\n",
    "P_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-15c85a4a121b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# results = model.fit_regularized()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0mNot\u001b[0m \u001b[0mimplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \"\"\"\n\u001b[0;32m-> 1117\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Attempt at ridge and lasso regression... alas statsmodels is not a good package for this:\n",
    "    # https://groups.google.com/forum/#!topic/pystatsmodels/nC_boeczVWo\n",
    "    # https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.fit_regularized.html\n",
    "\n",
    "x = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, x) #.fit_regularized(method='elastic_net', alpha=0.0, L1_wt=1.0)\n",
    "results = model.fit_regularized()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
